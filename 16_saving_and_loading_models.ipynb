{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving and Loading models\n",
    "\n",
    "It is important to understand how to save a model so we can reuse it without running the entire training pipeline over and over, as well as the various formats, and how PyTorch handles this process. We could also for example, save the best state of a model during the training pipeline to ensure best results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 3 methods we can use to save/load a model\n",
    "\n",
    "- 1 <br>\n",
    "    `torch.save(arg, PATH)`\n",
    "- 2 <br>\n",
    "    `torch.load(PATH)`\n",
    "- 3 <br>\n",
    "    `model.load_state_dict(arg)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.save` can use tensors, models, or dictionaries as parameters for saving. It makes use of Python's pickle model to serialize the model. <br>\n",
    "\n",
    "The lazy method to use this would be like:\n",
    "```py\n",
    "torch.save(model, PATH)\n",
    "model = torch.load(PATH)\n",
    "model.eval()  # Evaluation mode\n",
    "```\n",
    "The disadvantage of this approach is that the serialized data is bound to the specific classes and exact directory structure used when the model is saved.\n",
    "<br>\n",
    "The recommended way of saving our model is like so:\n",
    "```py\n",
    "torch.save(model.state_dict(), PATH)  # Saves the parameters\n",
    "# Model must be created again with parameters\n",
    "model = Model(*args, **kwargs)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "```\n",
    "Now let's see some examples in practice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_pred = torch.sigmoid(self.linear(x))\n",
    "        return y_pred\n",
    "\n",
    "# This is a super simple example model\n",
    "model = Model(n_input_features=6)\n",
    "# Training loop would go here\n",
    "# ...\n",
    "\n",
    "FILE = \"model.pth\"\n",
    "torch.save(model, FILE)  # LAZY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3934, -0.3836,  0.0619, -0.1382, -0.0944, -0.3254]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2454], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = torch.load(FILE)\n",
    "model.eval()  # Evaluation mode\n",
    "\n",
    "# Use the model anyhow\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Actual recommended method\n",
    "torch.save(model.state_dict(), FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3934, -0.3836,  0.0619, -0.1382, -0.0944, -0.3254]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.2454], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Load from state dict\n",
    "loaded_model = Model(n_input_features=6)  # Reinstantiate\n",
    "loaded_model.load_state_dict(torch.load(FILE))\n",
    "loaded_model.eval()  # Evaluation mode\n",
    "\n",
    "# Use the model anyhow\n",
    "for param in model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('linear.weight', tensor([[-0.3934, -0.3836,  0.0619, -0.1382, -0.0944, -0.3254]])), ('linear.bias', tensor([-0.2454]))])\n"
     ]
    }
   ],
   "source": [
    "# State dict stuff\n",
    "print(model.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# We can create checkpoints to stop during training\n",
    "# We make a checkpoint dict\n",
    "checkpoint = {\n",
    "    \"epoch\": 90,  # Example\n",
    "    \"model_state\": model.state_dict(),\n",
    "    \"optim_state\": optimizer.state_dict(),\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, \"checkpoint.pth\")\n",
    "\n",
    "# Load checkpoint\n",
    "loaded_checkpoint = torch.load(\"checkpoint.pth\")\n",
    "epoch = loaded_checkpoint[\"epoch\"]\n",
    "\n",
    "# Make new model to continue training\n",
    "model = Model(n_input_features=6)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0)  # lr can be whatever for now\n",
    "\n",
    "model.load_state_dict(checkpoint[\"model_state\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optim_state\"])\n",
    "\n",
    "# Can continue from current epoch stored in state_dict\n",
    "# Note device interoperability matters (CPU/GPU). Check the docs."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
