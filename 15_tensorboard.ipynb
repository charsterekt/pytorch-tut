{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard\n",
    "\n",
    "Tensorboard is a visualization and inspection tool created by TensorFlow, which can also be integrated with PyTorch to visualize and inspect our pipeline and models. In this notebook, the code is nearly identical to the code from notebook 12: feed forward net. We are using it as an example for how to get started with Tensorboard. <br>\n",
    "\n",
    "To get started, run tensorboard in the terminal with `tensorboard --logdir=runs` where `logdir` is the directory where run logs are stored. Tensorboard will be started on localhost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary write for tensorboard\n",
    "writer = SummaryWriter(\"runs/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 784  # 28 x 28 is the image size, will be flattened into a 1D tensor\n",
    "hidden_size = 100  # Number of nodes in the hidden layer\n",
    "num_classes = 10  # Digits from 0 - 9\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([100, 1, 28, 28]), Labels shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "training_dataset = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "    transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, \n",
    "    transform=transforms.ToTensor())\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=batch_size,\n",
    "    shuffle=True, num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "    shuffle=True, num_workers=0)\n",
    "\n",
    "# View a single batch\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(f'Shape: {samples.shape}, Labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the sample is 100 (batch size), 1 is for a singular channel (no colour channels), 28, 28 is the image array (28x28). Each class label has 1 value, hence the labels being a tensor of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot this\n",
    "for i in range(6):  # 6 samples\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')  # [0] for the first color channel\n",
    "plt.show()\n",
    "\n",
    "# Apart from plotting we can also add the images to the tensorboard\n",
    "image_grid = torchvision.utils.make_grid(samples)\n",
    "writer.add_image(\"MNIST images example\", image_grid)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a neural network\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):  # Num classes = output size\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # Layers\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)  # Output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        # No softmax as we're applying cross entropy loss\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Model graph\n",
    "sample_data = samples.reshape(-1, 28*28).to(device)\n",
    "writer.add_graph(model, sample_data)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping...\n",
      "Epoch 1/2, Step 100/600, Loss: 0.0378\n",
      "Epoch 1/2, Step 200/600, Loss: 0.0859\n",
      "Epoch 1/2, Step 300/600, Loss: 0.0469\n",
      "Epoch 1/2, Step 400/600, Loss: 0.0463\n",
      "Epoch 1/2, Step 500/600, Loss: 0.0219\n",
      "Epoch 1/2, Step 600/600, Loss: 0.0175\n",
      "Epoch 2/2, Step 100/600, Loss: 0.0596\n",
      "Epoch 2/2, Step 200/600, Loss: 0.0518\n",
      "Epoch 2/2, Step 300/600, Loss: 0.0712\n",
      "Epoch 2/2, Step 400/600, Loss: 0.0349\n",
      "Epoch 2/2, Step 500/600, Loss: 0.0108\n",
      "Epoch 2/2, Step 600/600, Loss: 0.1143\n",
      "Accuracy: 97.4900%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "# Adding Tensorboard diagnostics\n",
    "running_loss = 0.0\n",
    "running_correct_preds = 0\n",
    "\n",
    "print(\"Reshaping...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape the images from 100, 1, 28, 28 to 100, 784\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss_value = loss(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running metrics\n",
    "        running_loss += loss_value.item()\n",
    "        _, predictions = torch.max(outputs, 1)\n",
    "        running_correct_preds += torch.sum(predictions == labels).sum().item()\n",
    "        # Print info\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Step {i + 1}/{n_total_steps}, Loss: {loss_value.item():.4f}')\n",
    "            # Calculate the mean and add it to the tensorboard\n",
    "            writer.add_scalar('Training Loss', running_loss / 100, epoch * n_total_steps + i)\n",
    "            writer.add_scalar('Accuracy', running_correct_preds / 100, epoch * n_total_steps + i)\n",
    "            # Reset\n",
    "            running_loss = 0.0\n",
    "            running_correct_preds = 0\n",
    "\n",
    "\n",
    "# Testing and Evaluation of the model\n",
    "# Create a list to store labels. This will help in implementing a precision recall curve on tensorboard\n",
    "diag_labels = []\n",
    "preds = []\n",
    "\n",
    "# Don't compute gradients for these steps\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        # Reshape\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predictions = torch.max(outputs, 1)  # Along first dimension\n",
    "        n_samples += labels.shape[0]  # Will give number of samples in current batch\n",
    "        # n_samples += labels.size(0) is also valid\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "\n",
    "        # Diagnostics\n",
    "        class_predictions = [F.softmax(output, dim=0) for output in outputs]\n",
    "        preds.append(class_predictions)\n",
    "        diag_labels.append(predictions)\n",
    "        \n",
    "    # Diagnostic conversion\n",
    "    diag_labels = torch.cat(diag_labels)  # Concatenate all labels along this dimension into a 1D tensor\n",
    "    preds = torch.cat([torch.stack(batch) for batch in preds])\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "    print(f'Accuracy: {acc:.4f}%')\n",
    "\n",
    "    # Add the precision recall curve to tensorboard\n",
    "    classes = range(10)\n",
    "    for i in classes:\n",
    "        labels_i = diag_labels == i\n",
    "        preds_i = preds[:, i]  # All the samples for class i\n",
    "\n",
    "        writer.add_pr_curve(str(i), labels_i, preds_i, global_step=0)\n",
    "        writer.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
