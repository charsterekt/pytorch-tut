{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed Forward Network\n",
    "\n",
    "We will make a multi layer neural network using things we've learnt in the previous notebooks. We will be working with the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device config\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "input_size = 784  # 28 x 28 is the image size, will be flattened into a 1D tensor\n",
    "hidden_size = 100  # Number of nodes in the hidden layer\n",
    "num_classes = 10  # Digits from 0 - 9\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: torch.Size([100, 1, 28, 28]), Labels shape: torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "# Import MNIST data\n",
    "training_dataset = torchvision.datasets.MNIST(root='./data', train=True, \n",
    "    transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, \n",
    "    transform=transforms.ToTensor())\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(dataset=training_dataset, batch_size=batch_size,\n",
    "    shuffle=True, num_workers=0)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size,\n",
    "    shuffle=True, num_workers=0)\n",
    "\n",
    "# View a single batch\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(f'Shape: {samples.shape}, Labels shape: {labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The size of the sample is 100 (batch size), 1 is for a singular channel (no colour channels), 28, 28 is the image array (28x28). Each class label has 1 value, hence the labels being a tensor of 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot this\n",
    "for i in range(6):  # 6 samples\n",
    "    plt.subplot(2, 3, i+1)\n",
    "    plt.imshow(samples[i][0], cmap='gray')  # [0] for the first color channel\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a neural network\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):  # Num classes = output size\n",
    "        super(NeuralNet, self).__init__()\n",
    "        # Layers\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "        self.layer2 = nn.Linear(hidden_size, num_classes)  # Output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "        # No softmax as we're applying cross entropy loss\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the model\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and Optimizer\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reshaping...\n",
      "Epoch 1/2, Step 100/600, Loss: 0.0853\n",
      "Epoch 1/2, Step 200/600, Loss: 0.0394\n",
      "Epoch 1/2, Step 300/600, Loss: 0.0513\n",
      "Epoch 1/2, Step 400/600, Loss: 0.1161\n",
      "Epoch 1/2, Step 500/600, Loss: 0.0467\n",
      "Epoch 1/2, Step 600/600, Loss: 0.0803\n",
      "Epoch 2/2, Step 100/600, Loss: 0.0271\n",
      "Epoch 2/2, Step 200/600, Loss: 0.0799\n",
      "Epoch 2/2, Step 300/600, Loss: 0.0390\n",
      "Epoch 2/2, Step 400/600, Loss: 0.0154\n",
      "Epoch 2/2, Step 500/600, Loss: 0.0319\n",
      "Epoch 2/2, Step 600/600, Loss: 0.0471\n",
      "Accuracy: 97.5100%\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "print(\"Reshaping...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Reshape the images from 100, 1, 28, 28 to 100, 784\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss_value = loss(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print info\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch {epoch + 1}/{num_epochs}, Step {i + 1}/{n_total_steps}, Loss: {loss_value.item():.4f}')\n",
    "\n",
    "\n",
    "# Testing and Evaluation of the model\n",
    "# Don't compute gradients for these steps\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        # Reshape\n",
    "        images = images.reshape(-1, 28 * 28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "\n",
    "        _, predictions = torch.max(outputs, 1)  # Along first dimension\n",
    "        n_samples += labels.shape[0]  # Will give number of samples in current batch\n",
    "        # n_samples += labels.size(0) is also valid\n",
    "        n_correct += (predictions == labels).sum().item()\n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "\n",
    "    print(f'Accuracy: {acc:.4f}%')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
