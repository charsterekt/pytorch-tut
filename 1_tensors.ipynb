{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "\n",
    "Everything in PyTorch works on the basic unit of a `Tensor`. We will be working with these basic units in this notebook. Tensors are multidimensional units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imported successfully\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "print(\"Imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.])\n",
      "tensor([0.0000e+00, 6.6161e-06, 5.6052e-45])\n"
     ]
    }
   ],
   "source": [
    "x = torch.empty(1)  # A one dimensional tensor is like a scalar value\n",
    "# This tensor is empty with no value given to it for now\n",
    "print(x)\n",
    "# This is a 1D tensor with one element\n",
    "# We can also for example have a 1D tensor with 3 elements\n",
    "a = torch.empty(3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8009e+24],\n",
      "        [4.5916e-41, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00]])\n",
      "tensor([[[-5.0940e-02,  7.1606e-43,  0.0000e+00,  7.1606e-43],\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.1019e-44,  0.0000e+00],\n",
      "         [-8.8030e-02,  7.1606e-43,  0.0000e+00,  7.1606e-43],\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.1019e-44,  0.0000e+00]],\n",
      "\n",
      "        [[-6.4657e-02,  7.1606e-43,  0.0000e+00,  7.1606e-43],\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.1019e-44,  0.0000e+00],\n",
      "         [-1.5421e-01,  7.1606e-43,  0.0000e+00,  7.1606e-43],\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.1019e-44,  0.0000e+00]],\n",
      "\n",
      "        [[-1.0681e-01,  7.1606e-43,  0.0000e+00,  7.1606e-43],\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.1019e-44,  0.0000e+00],\n",
      "         [-3.7344e+00,  7.1606e-43,  0.0000e+00,  7.1606e-43],\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.1019e-44,  0.0000e+00]],\n",
      "\n",
      "        [[-1.1874e-01,  7.1606e-43,  0.0000e+00,  7.1606e-43],\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.1019e-44,  0.0000e+00],\n",
      "         [-3.6191e+00,  7.1606e-43,  0.0000e+00,  7.1606e-43],\n",
      "         [ 0.0000e+00,  0.0000e+00,  2.1019e-44,  0.0000e+00]]])\n"
     ]
    }
   ],
   "source": [
    "# We can have tensors in 2D and 3D\n",
    "y = torch.empty(3, 5)  # 3 rows and 5 columns\n",
    "z = torch.empty(4, 4, 4) # 4x4x4 tensor, but it's still 3 dimensional\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.8401, 0.5294],\n",
       "        [0.2684, 0.2848]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can create a tensor with random values like so:\n",
    "b = torch.rand(2, 2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Similar to numpy, we can have a tensor of zeroes\n",
    "c = torch.zeros(2, 2)\n",
    "# But also a tensor of ones\n",
    "d = torch.ones(2, 2)\n",
    "print(c)\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default tensors have the datatype of `torch.float32`. We can check this if we print out the `dtype` attribute of the tensor. We can change this type by explicitly calling an argument to change it when creating a tensor. <br>\n",
    "\n",
    "Some of the types are:\n",
    "- int\n",
    "- double\n",
    "- float64\n",
    "- float32 (default)\n",
    "- float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [1, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(d.dtype)\n",
    "e = torch.ones(2, 2, dtype=torch.int)\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can check the size of a tensor like so:\n",
    "e.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000, 0.1000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can construct a tensor using data like a python list\n",
    "f = torch.tensor([2.5, 0.1])\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7003, 0.5694],\n",
      "        [0.3961, 0.6893]])\n",
      "tensor([[0.5705, 0.4116],\n",
      "        [0.1332, 0.7234]])\n",
      "tensor([[1.2708, 0.9810],\n",
      "        [0.5293, 1.4128]])\n",
      "tensor([[1.2708, 0.9810],\n",
      "        [0.5293, 1.4128]])\n",
      "tensor([[1.2708, 0.9810],\n",
      "        [0.5293, 1.4128]])\n"
     ]
    }
   ],
   "source": [
    "g = torch.rand(2, 2)\n",
    "f = torch.rand(2, 2)\n",
    "print(g)\n",
    "print(f)\n",
    "\n",
    "# Simple addition: (element wise)\n",
    "print(g + f) \n",
    "# Another way to do this is:\n",
    "print(torch.add(g, f))\n",
    "# If we want to do in place addition:\n",
    "f.add_(g)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important to note: \n",
    "In PyTorch, every method with a trailing _ (underscore), will perform an in-place operation. I.E. it will modify the first value by performing the operation on it instead of storing the result in a var for example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly:\n",
    "\n",
    "```py\n",
    "a = b - c\n",
    "a = torch.sub(b, c)\n",
    "a = b * c\n",
    "a = torch.mul(b, c)\n",
    "a = b / c\n",
    "a = torch.div(b, c)\n",
    "```\n",
    "\n",
    "And if we were going in place:\n",
    "\n",
    "```py\n",
    "b.sub_(c)\n",
    "b.mul_(c)\n",
    "b.div_(c)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3232, 0.9370, 0.5775],\n",
      "        [0.0815, 0.0532, 0.7919],\n",
      "        [0.5434, 0.5884, 0.1220],\n",
      "        [0.6453, 0.7970, 0.4350],\n",
      "        [0.5840, 0.8801, 0.4985]])\n",
      "tensor([0.3232, 0.0815, 0.5434, 0.6453, 0.5840])\n",
      "tensor([0.0815, 0.0532, 0.7919])\n",
      "tensor(0.0532)\n",
      "0.053211748600006104\n"
     ]
    }
   ],
   "source": [
    "# Now for some slicing operations\n",
    "# These should be similar to numpy arrays\n",
    "tensor1 = torch.rand(5, 3)\n",
    "print(tensor1)\n",
    "print(tensor1[:, 0])  # All rows but only column 0\n",
    "print(tensor1[1, :])  # Row 1 but all columns\n",
    "\n",
    "# We can also get only one element like so\n",
    "print(tensor1[1, 1])\n",
    "# NOTE: if we have a tensor with ONLY one element, we can call item()\n",
    "print(tensor1[1, 1].item())  # This will return the actual value\n",
    "# THIS ONLY WORKS FOR 1 X 1 (scalar) tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3887, 0.7408, 0.8059, 0.1847],\n",
      "        [0.1911, 0.0798, 0.1407, 0.9136],\n",
      "        [0.9969, 0.9292, 0.7366, 0.1348],\n",
      "        [0.1282, 0.6088, 0.3945, 0.0687]])\n",
      "tensor([0.3887, 0.7408, 0.8059, 0.1847, 0.1911, 0.0798, 0.1407, 0.9136, 0.9969,\n",
      "        0.9292, 0.7366, 0.1348, 0.1282, 0.6088, 0.3945, 0.0687])\n",
      "tensor([[0.3887, 0.7408, 0.8059, 0.1847, 0.1911, 0.0798, 0.1407, 0.9136],\n",
      "        [0.9969, 0.9292, 0.7366, 0.1348, 0.1282, 0.6088, 0.3945, 0.0687]])\n"
     ]
    }
   ],
   "source": [
    "tensor2 = torch.rand(4, 4)\n",
    "print(tensor2)\n",
    "\n",
    "# Reshape with view method\n",
    "reshaped = tensor2.view(16)\n",
    "print(reshaped)\n",
    "# The number of elements must remain the same, 4x4 2D = 16 1D\n",
    "\n",
    "reshaped2 = tensor2.view(-1, 8)\n",
    "print(reshaped2)\n",
    "# By giving -1 pytorch will autodetect the right size by calculating for that dimension\n",
    "# In this case it must be a 2x8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting between Numpy and Torch tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# torch tensor\n",
    "torchtens = torch.ones(5)\n",
    "print(torchtens)\n",
    "# convert to numpy:\n",
    "nptens = torchtens.numpy()\n",
    "print(nptens)\n",
    "\n",
    "# Convert back:\n",
    "torchtens2 = torch.from_numpy(nptens)  # Optional dtype arg\n",
    "print(torchtens2)  # default floa64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important\n",
    "NOTE that if the tensor is on the GPU, converting a tensor will work but both the tensors, numpy and torch, will have the same memory location, so any in place operations will change the values of both. Additionally, numpy tensors can only handle CPU whereas torch ones can handle GPU as well, which can cause complications during interconversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# By default the requires_grad argument is False\n",
    "optimized_tensor = torch.ones(5, requires_grad=True)  # can be set true\n",
    "print(optimized_tensor)\n",
    "\n",
    "# This is needed for tensors that are to be optimized\n",
    "# Pytorch needs to know so it can calc the gradient"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4ce0e62306dd6a5716965d4519ada776f947e6dfc145b604b11307c10277ef29"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
